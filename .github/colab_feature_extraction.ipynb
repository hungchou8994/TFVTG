{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NExT-GQA — BLIP-2 Feature Extraction\n",
        "Chạy notebook này trên **Google Colab** với GPU (T4 hoặc A100).\n",
        "\n",
        "**Checklist trước khi chạy:**\n",
        "- [ ] Runtime → Change runtime type → **GPU** (T4 hoặc A100)\n",
        "- [ ] Google Drive đã có thư mục `vidor_videos/` (cấu trúc VidOR gốc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Kiểm tra GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Clone repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "REPO_URL = 'https://github.com/YOUR_USERNAME/TFVTG.git'  # <-- đổi lại\n",
        "REPO_DIR = '/content/TFVTG'\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    !git clone {REPO_URL} {REPO_DIR}\n",
        "else:\n",
        "    print('Repo already cloned, pulling latest...')\n",
        "    !git -C {REPO_DIR} pull\n",
        "\n",
        "%cd {REPO_DIR}\n",
        "!ls dataset/nextgqa/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Cấu hình đường dẫn\n",
        "Chỉ cần chỉnh **2 biến** bên dưới."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Thư mục VidOR videos trên Drive\n",
        "# Cấu trúc bên trong: {folder}/{video_id}.mp4\n",
        "# Ví dụ: .../nextqa/videos/0034/4740345442.mp4\n",
        "DRIVE_VIDOR_ROOT = '/content/drive/MyDrive/KLTN/VideoMind-Dataset/nextqa/videos'  # <-- đổi nếu cần\n",
        "\n",
        "# Thư mục lưu .npy features trên Drive (để không mất khi session reset)\n",
        "DRIVE_FEATURES_OUT = '/content/drive/MyDrive/KLTN/nextgqa_blip2_features'  # <-- đổi nếu cần\n",
        "\n",
        "print('VIDOR_ROOT   :', DRIVE_VIDOR_ROOT)\n",
        "print('FEATURES_OUT :', DRIVE_FEATURES_OUT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Symlink videos + features vào repo\n",
        "Annotation files đã có trong repo (đã push), chỉ cần symlink phần nặng."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Tạo thư mục output trên Drive nếu chưa có\n",
        "os.makedirs(DRIVE_FEATURES_OUT, exist_ok=True)\n",
        "\n",
        "nextgqa_dir = f'{REPO_DIR}/dataset/nextgqa'\n",
        "\n",
        "# Symlink videos (VidOR) → không copy, quá nặng\n",
        "videos_link = f'{nextgqa_dir}/videos'\n",
        "if not os.path.exists(videos_link):\n",
        "    os.symlink(DRIVE_VIDOR_ROOT, videos_link)\n",
        "    print(f'Symlinked videos: {videos_link} -> {DRIVE_VIDOR_ROOT}')\n",
        "else:\n",
        "    print(f'videos symlink already exists')\n",
        "\n",
        "# Symlink blip2_features → lưu thẳng vào Drive qua symlink\n",
        "features_link = f'{nextgqa_dir}/blip2_features'\n",
        "if not os.path.exists(features_link):\n",
        "    os.symlink(DRIVE_FEATURES_OUT, features_link)\n",
        "    print(f'Symlinked features: {features_link} -> {DRIVE_FEATURES_OUT}')\n",
        "else:\n",
        "    print(f'blip2_features symlink already exists')\n",
        "\n",
        "print('\\ndataset/nextgqa/ contents:')\n",
        "!ls -la {nextgqa_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Sanity check — tìm thử vài videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json, csv, os\n",
        "\n",
        "nextgqa_dir = f'{REPO_DIR}/dataset/nextgqa'\n",
        "\n",
        "with open(f'{nextgqa_dir}/map_vid_vidorID.json') as f:\n",
        "    mapping = json.load(f)\n",
        "\n",
        "test_vids = set()\n",
        "with open(f'{nextgqa_dir}/test.csv') as f:\n",
        "    for row in csv.DictReader(f):\n",
        "        test_vids.add(row['video_id'])\n",
        "\n",
        "print(f'Test videos: {len(test_vids)}')\n",
        "print('\\nChecking first 5 video paths:')\n",
        "found = 0\n",
        "for vid in list(test_vids)[:5]:\n",
        "    rel = mapping.get(vid)\n",
        "    if not rel:\n",
        "        print(f'  {vid}: NO MAPPING')\n",
        "        continue\n",
        "    folder, vid_id = rel.split('/')\n",
        "    found_path = None\n",
        "    for ext in ['.mp4', '.avi', '.mkv']:\n",
        "        # Flat: {folder}/{video_id}.ext  (most common)\n",
        "        p = f'{DRIVE_VIDOR_ROOT}/{folder}/{vid_id}{ext}'\n",
        "        if os.path.exists(p):\n",
        "            found_path = p\n",
        "            break\n",
        "        # Nested: {folder}/{video_id}/{video_id}.ext  (VidOR original)\n",
        "        p2 = f'{DRIVE_VIDOR_ROOT}/{folder}/{vid_id}/{vid_id}{ext}'\n",
        "        if os.path.exists(p2):\n",
        "            found_path = p2\n",
        "            break\n",
        "    if found_path:\n",
        "        print(f'  {vid} -> FOUND: {found_path}')\n",
        "        found += 1\n",
        "    else:\n",
        "        print(f'  {vid} -> NOT FOUND (checked {DRIVE_VIDOR_ROOT}/{folder}/{vid_id}[.mp4|/...])')\n",
        "\n",
        "print(f'\\nFound {found}/5 — nếu 0/5 kiểm tra lại DRIVE_VIDOR_ROOT')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Install dependencies\n",
        "> ⚠️ `salesforce-lavis` mất ~5-10 phút, chỉ cần chạy 1 lần per session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Pin tokenizers (pre-built wheel, tránh build Rust)\n",
        "!pip install \"tokenizers==0.15.2\" -q --prefer-binary\n",
        "\n",
        "# 2. Cài salesforce-lavis (BLIP-2)\n",
        "!pip install salesforce-lavis -q --prefer-binary\n",
        "\n",
        "# 3. Fix numpy 2.x vs opencv ABI conflict:\n",
        "#    salesforce-lavis cài opencv 4.5.x (compile với numpy 1.x) → crash với numpy 2.x\n",
        "#    Upgrade opencv lên version hỗ trợ numpy 2.x\n",
        "!pip install \"opencv-python-headless>=4.9.0\" -q --prefer-binary\n",
        "\n",
        "# 4. Cài decord\n",
        "!pip install decord tqdm -q\n",
        "\n",
        "print(\"Done! Verifying cv2 import...\")\n",
        "import cv2\n",
        "print(f\"  cv2 version: {cv2.__version__} ✓\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Chạy Feature Extraction\n",
        "\n",
        "- Extract cả **val + test** (1557 videos tổng)\n",
        "- Tự **resume** nếu session bị ngắt — chạy lại cell này là đủ\n",
        "- Features lưu thẳng vào Drive qua symlink → an toàn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python feature_extraction_nextgqa.py \\\n",
        "    --vidor_root {DRIVE_VIDOR_ROOT} \\\n",
        "    --save_root  dataset/nextgqa/blip2_features \\\n",
        "    --splits test \\\n",
        "    --fps 3 \\\n",
        "    --batch_size 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Kiểm tra kết quả"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np, os\n",
        "\n",
        "npy_files = [f for f in os.listdir(DRIVE_FEATURES_OUT) if f.endswith('.npy')]\n",
        "print(f'Extracted: {len(npy_files)} / 1557 videos')\n",
        "\n",
        "if npy_files:\n",
        "    sample = np.load(os.path.join(DRIVE_FEATURES_OUT, npy_files[0]))\n",
        "    print(f'Sample shape : {sample.shape}  (expected [T, 32, 256])')\n",
        "    print(f'dtype        : {sample.dtype}   (expected float16)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Bước 6: Grounder — TFVTG temporal proposals\n",
        "\n",
        "Sau khi extract features xong, chạy Grounder để sinh top-5 temporal proposals cho mỗi câu hỏi.\n",
        "- Input : `llm_outputs_test.json` (query rewrite từ Bước 5) + BLIP-2 features\n",
        "- Output: `grounder_outputs_test.json` (~5553 entries, mỗi entry có `top5_proposals`)\n",
        "- Tự **resume** nếu bị ngắt\n",
        "- Cần GPU (BLIP-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dry run trước: 10 questions để kiểm tra output format\n",
        "!python -m nextgqa.grounder --split test --dry_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chạy full (5553 questions) — tự resume nếu ngắt\n",
        "!PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True \\\n",
        "python -m nextgqa.grounder --split test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kiểm tra kết quả Grounder\n",
        "import json\n",
        "\n",
        "with open('/content/TFVTG/dataset/nextgqa/grounder_outputs_test.json') as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "print(f'Total entries: {len(results)} / 5553')\n",
        "\n",
        "# Show sample\n",
        "r = results[0]\n",
        "print(f'\\nSample:')\n",
        "print(f'  video_id  : {r[\"video_id\"]}')\n",
        "print(f'  qid       : {r[\"qid\"]}')\n",
        "print(f'  question  : {r[\"question\"][:60]}...')\n",
        "print(f'  type      : {r[\"type\"]}')\n",
        "print(f'  duration  : {r[\"duration\"]}s')\n",
        "print(f'  gt_segments: {r[\"gt_segments\"]}')\n",
        "print(f'  top5_proposals:')\n",
        "for i, p in enumerate(r['top5_proposals']):\n",
        "    print(f'    #{i+1}: [{p[0]:.1f}s, {p[1]:.1f}s] conf={p[2]:.3f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
